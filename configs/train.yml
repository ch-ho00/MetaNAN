### INPUT
expname                     : DegAE_AllCondRenderer_discrimScratch_annealTarget_preBPN_weightSumFilter0.9998_perImg_ftEmbed_embedLoss1e3_adv5e-3_novelView #denoise # MetaDegAE #NAN_SrcFeatTransform_2e-2 #AE_preTransform_reconst_5x_anneal_5e-2_5e-2 #_2e-5 # AE_reconstNoisySrc_0_5e-1 #   #AE_wreconstVol_conv1x1_woSigmoid_1e-1_1e-1
render_stride               : 2  # used in evaluation
distributed                 : False

## dataset
train_dataset               : llff
eval_dataset                : llff_test
eval_scenes                 : [fern, trex, leaves, horns] #[fern, orchids, flower, horns, leaves, room, trex, fortress]

### TRAINING
n_iters                     : 255000
N_rand                      : 512
lrate_feature               : 0.001
lrate_mlp                   : 0.0005
lrate_decay_factor          : 0.5
lrate_decay_steps           : 50000
losses                      : [l2, l1, l1_grad, ssim]
losses_weights              : [0,  1,  0,       0]
workers                     : 0

degae_feat                  : True
degae_feat_ckpt             : ./ckpts/0619.pth #./ckpts/model_045000.pth
coarse_feat_dim             : 32
fine_feat_dim               : 32
img_size                    : 256
meta_module                 : False
downscale_input_img         : False #True
weightsum_filtered          : True
lambda_embed_loss           : 1000
bpn_prenet                  : True
bpn_per_img                 : True
ft_embed_fc                 : True
cond_renderer               : True
lambda_adv                  : 0.005
# discrim_ckpt_path           : ./ckpts/discrim_100000.pth

### TESTING
chunk_size                  : 2048 #2048 # can be bigger depend on the gpu memory

### RENDERING
N_importance                : 64
N_samples                   : 64
inv_uniform                 : True
white_bkgd                  : False

### CONSOLE AND TENSORBOARD
i_img                       : 3000
i_print                     : 100
i_tb                        : 20
i_weights                   : 5000

### additional
#ckpt_path                   : out/NAN/model_255000.pth   # use this if you want to train from a specific checkpoint.
no_load_opt                 : False
no_load_scheduler           : False
sup_clean                   : True

include_target              : False  # set to False if you want to synthesize images rather than denoise the images
eval_gain                    : [20, 16, 8]
std                         : [-3.0, -0.5, -2.0, -0.5]


views_attn                  : True
kernel_size                 : [3, 3]
pre_net                     : True
noise_feat                  : True
rgb_weights                 : True

local_rank                  : 0
